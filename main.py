import asyncio
import base64
import json
import os
import re
import sys
import uuid
from datetime import datetime
from typing import Any

import aiohttp
import formatters

import astrbot.api.message_components as Comp
from astrbot.api import AstrBotConfig, logger
from astrbot.api.event import AstrMessageEvent, MessageChain, filter
from astrbot.api.star import Context, Star, register

from .webhook_server import GitHubWebhookServer

PLUGIN_DIR = os.path.dirname(__file__)
if PLUGIN_DIR not in sys.path:
    sys.path.insert(0, PLUGIN_DIR)

GITHUB_URL_PATTERN = r"https://github\.com/[\w\-]+/[\w\-]+(?:/(pull|issues)/\d+)?"
GITHUB_REPO_OPENGRAPH = "https://opengraph.githubassets.com/{hash}/{appendix}"
STAR_HISTORY_URL = "https://api.star-history.com/svg?repos={identifier}&type=Date"
GITHUB_API_URL = "https://api.github.com/repos/{repo}"
GITHUB_README_API_URL = (
    "https://api.github.com/repos/{repo}/readme"  # æ–°å¢ README API URL
)
GITHUB_ISSUES_API_URL = "https://api.github.com/repos/{repo}/issues"
GITHUB_ISSUE_API_URL = "https://api.github.com/repos/{repo}/issues/{issue_number}"
GITHUB_PR_API_URL = "https://api.github.com/repos/{repo}/pulls/{pr_number}"
GITHUB_RATE_LIMIT_URL = "https://api.github.com/rate_limit"

# Path for storing subscription data
SUBSCRIPTION_FILE = "data/github_subscriptions.json"
# Path for storing default repo data
DEFAULT_REPO_FILE = "data/github_default_repos.json"


@register(
    "astrbot_plugin_github_cards",
    "Soulter",
    "æ ¹æ®ç¾¤èŠä¸­ GitHub ç›¸å…³é“¾æ¥è‡ªåŠ¨å‘é€ GitHub OpenGraph å›¾ç‰‡ï¼Œæ”¯æŒè®¢é˜…ä»“åº“çš„ Issue å’Œ PR",
    "1.1.0",
    "https://github.com/Soulter/astrbot_plugin_github_cards",
)
class MyPlugin(Star):
    def __init__(self, context: Context, config: AstrBotConfig | None = None):
        super().__init__(context)
        self.config = config or {}
        self.subscriptions = self._load_subscriptions()
        self.default_repos = self._load_default_repos()
        self.last_check_time = {}  # Store the last check time for each repo
        self.use_lowercase = self.config.get("use_lowercase_repo", True)
        self.github_token = self.config.get("github_token", "")
        self.check_interval = self.config.get("check_interval", 30)
        self.enable_webhook = bool(self.config.get("enable_webhook", False))
        self.webhook_host = self.config.get("webhook_host", "0.0.0.0")
        self.webhook_port = int(self.config.get("webhook_port", 6192))
        self.webhook_secret = self.config.get("webhook_secret", "")
        self.webhook_path = self.config.get("webhook_path", "/github/webhook")
        self.webhook_server: Any | None = None
        self.task: asyncio.Task[Any] | None = None

        if self.enable_webhook:
            server = GitHubWebhookServer(
                plugin=self,
                host=self.webhook_host,
                port=self.webhook_port,
                secret=self.webhook_secret,
                path=self.webhook_path,
            )
            self.webhook_server = server
            server.start()
            logger.info("GitHub Cards Plugin åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨ Webhook æ¨¡å¼")
        else:
            # Start background task to check for updates when webhook is disabled
            self.task = asyncio.create_task(self._check_updates_periodically())
            logger.info(
                f"GitHub Cards Pluginåˆå§‹åŒ–å®Œæˆï¼Œæ£€æŸ¥é—´éš”: {self.check_interval}åˆ†é’Ÿ"
            )

    def _load_subscriptions(self) -> dict[str, list[str]]:
        """Load subscriptions from JSON file"""
        if os.path.exists(SUBSCRIPTION_FILE):
            try:
                with open(SUBSCRIPTION_FILE, encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½è®¢é˜…æ•°æ®å¤±è´¥: {e}")
        return {}

    def _save_subscriptions(self):
        """Save subscriptions to JSON file"""
        try:
            os.makedirs(os.path.dirname(SUBSCRIPTION_FILE), exist_ok=True)
            with open(SUBSCRIPTION_FILE, "w", encoding="utf-8") as f:
                json.dump(self.subscriptions, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜è®¢é˜…æ•°æ®å¤±è´¥: {e}")

    def _load_default_repos(self) -> dict[str, str]:
        """Load default repo settings from JSON file"""
        if os.path.exists(DEFAULT_REPO_FILE):
            try:
                with open(DEFAULT_REPO_FILE, encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                logger.error(f"åŠ è½½é»˜è®¤ä»“åº“æ•°æ®å¤±è´¥: {e}")
        return {}

    def _save_default_repos(self):
        """Save default repo settings to JSON file"""
        try:
            os.makedirs(os.path.dirname(DEFAULT_REPO_FILE), exist_ok=True)
            with open(DEFAULT_REPO_FILE, "w", encoding="utf-8") as f:
                json.dump(self.default_repos, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜é»˜è®¤ä»“åº“æ•°æ®å¤±è´¥: {e}")

    def _normalize_repo_name(self, repo: str) -> str:
        """Normalize repository name according to configuration"""
        return repo.lower() if self.use_lowercase else repo

    def _resolve_repo_key(self, repo: str) -> str | None:
        """Resolve stored subscription key that matches the provided repo name."""
        if repo in self.subscriptions:
            return repo

        normalized = self._normalize_repo_name(repo)
        for stored_repo in self.subscriptions.keys():
            if self._normalize_repo_name(stored_repo) == normalized:
                return stored_repo

        return None

    def _get_github_headers(self) -> dict[str, str]:
        """Get GitHub API headers with token if available"""
        headers = {"Accept": "application/vnd.github.v3+json"}
        if self.github_token:
            headers["Authorization"] = f"token {self.github_token}"
        return headers

    @filter.regex(GITHUB_URL_PATTERN)
    async def github_repo(self, event: AstrMessageEvent):
        """è§£æ Github ä»“åº“ä¿¡æ¯"""
        msg = event.message_str
        match = re.search(GITHUB_URL_PATTERN, msg)
        if not match:
            logger.debug("æœªèƒ½åœ¨æ¶ˆæ¯ä¸­è§£æåˆ° GitHub é“¾æ¥")
            return
        repo_url = match.group(0)
        repo_url = repo_url.replace("https://github.com/", "")
        hash_value = uuid.uuid4().hex
        opengraph_url = GITHUB_REPO_OPENGRAPH.format(hash=hash_value, appendix=repo_url)
        logger.info(f"ç”Ÿæˆçš„ OpenGraph URL: {opengraph_url}")

        try:
            yield event.image_result(opengraph_url)
        except Exception as e:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            yield event.plain_result("ä¸‹è½½ GitHub å›¾ç‰‡å¤±è´¥: " + str(e))
            return

    @filter.command("ghsub")
    async def subscribe_repo(self, event: AstrMessageEvent, repo: str):
        """è®¢é˜… GitHub ä»“åº“çš„ Issue å’Œ PRã€‚ä¾‹å¦‚: /ghsub Soulter/AstrBot"""
        if not self._is_valid_repo(repo):
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“åï¼Œæ ¼å¼ä¸º: ç”¨æˆ·å/ä»“åº“å")
            return

        # Normalize repository name
        normalized_repo = self._normalize_repo_name(repo)

        # Check if the repo exists
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    GITHUB_API_URL.format(repo=repo), headers=self._get_github_headers()
                ) as resp:
                    if resp.status != 200:
                        yield event.plain_result(f"ä»“åº“ {repo} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
                        return

                    repo_data = await resp.json()
                    display_name = repo_data.get("full_name", repo)
        except Exception as e:
            logger.error(f"è®¿é—® GitHub API å¤±è´¥: {e}")
            yield event.plain_result(f"æ£€æŸ¥ä»“åº“æ—¶å‡ºé”™: {str(e)}")
            return

        # Get the unique identifier for the subscriber
        subscriber_id = event.unified_msg_origin

        repo_key = self._resolve_repo_key(repo)
        if not repo_key:
            repo_key = normalized_repo if self.use_lowercase else display_name

        subscribers = self.subscriptions.setdefault(repo_key, [])

        if subscriber_id not in subscribers:
            subscribers.append(subscriber_id)
            self._save_subscriptions()

            # Fetch initial state for new subscription
            if not self.enable_webhook:
                await self._fetch_new_items(repo_key, None)

            yield event.plain_result(f"æˆåŠŸè®¢é˜…ä»“åº“ {display_name} çš„äº‹ä»¶æ›´æ–°ã€‚")
        else:
            yield event.plain_result(f"ä½ å·²ç»è®¢é˜…äº†ä»“åº“ {display_name}")

        # Set as default repo for this conversation
        self.default_repos[event.unified_msg_origin] = display_name
        self._save_default_repos()

    @filter.command("ghunsub")
    async def unsubscribe_repo(self, event: AstrMessageEvent, repo: str | None = None):
        """å–æ¶ˆè®¢é˜… GitHub ä»“åº“ã€‚ä¾‹å¦‚: /ghunsub Soulter/AstrBotï¼Œä¸æä¾›ä»“åº“ååˆ™å–æ¶ˆæ‰€æœ‰è®¢é˜…"""
        subscriber_id = event.unified_msg_origin

        if repo is None:
            # Unsubscribe from all repos
            unsubscribed = []
            for repo_name, subscribers in list(self.subscriptions.items()):
                if subscriber_id in subscribers:
                    subscribers.remove(subscriber_id)
                    unsubscribed.append(repo_name)
                    if not subscribers:
                        del self.subscriptions[repo_name]

            if unsubscribed:
                self._save_subscriptions()
                yield event.plain_result(
                    f"å·²å–æ¶ˆè®¢é˜…æ‰€æœ‰ä»“åº“: {', '.join(unsubscribed)}"
                )
            else:
                yield event.plain_result("ä½ æ²¡æœ‰è®¢é˜…ä»»ä½•ä»“åº“")
            return

        if not self._is_valid_repo(repo):
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“åï¼Œæ ¼å¼ä¸º: ç”¨æˆ·å/ä»“åº“å")
            return

        repo_key = self._resolve_repo_key(repo)
        if repo_key and subscriber_id in self.subscriptions.get(repo_key, []):
            self.subscriptions[repo_key].remove(subscriber_id)
            if not self.subscriptions[repo_key]:
                del self.subscriptions[repo_key]
            self._save_subscriptions()
            self.last_check_time.pop(repo_key, None)
            yield event.plain_result(f"å·²å–æ¶ˆè®¢é˜…ä»“åº“ {repo_key}")
        else:
            yield event.plain_result(f"ä½ æ²¡æœ‰è®¢é˜…ä»“åº“ {repo}")

    @filter.command("ghlist")
    async def list_subscriptions(self, event: AstrMessageEvent):
        """åˆ—å‡ºå½“å‰è®¢é˜…çš„ GitHub ä»“åº“"""
        subscriber_id = event.unified_msg_origin
        subscribed_repos = []

        for repo, subscribers in self.subscriptions.items():
            if subscriber_id in subscribers:
                subscribed_repos.append(repo)

        if subscribed_repos:
            yield event.plain_result(
                f"ä½ å½“å‰è®¢é˜…çš„ä»“åº“æœ‰: {', '.join(subscribed_repos)}"
            )
        else:
            yield event.plain_result("ä½ å½“å‰æ²¡æœ‰è®¢é˜…ä»»ä½•ä»“åº“")

    @filter.command("ghdefault", alias={"ghdef"})
    async def set_default_repo(self, event: AstrMessageEvent, repo: str | None = None):
        """è®¾ç½®é»˜è®¤ä»“åº“ã€‚ä¾‹å¦‚: /ghdefault Soulter/AstrBot"""
        if repo is None:
            # Show current default repo
            default_repo = self.default_repos.get(event.unified_msg_origin)
            if default_repo:
                yield event.plain_result(f"å½“å‰é»˜è®¤ä»“åº“ä¸º: {default_repo}")
            else:
                yield event.plain_result(
                    "å½“å‰æœªè®¾ç½®é»˜è®¤ä»“åº“ï¼Œå¯ä½¿ç”¨ /ghdefault ç”¨æˆ·å/ä»“åº“å è¿›è¡Œè®¾ç½®"
                )
            return

        if not self._is_valid_repo(repo):
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“åï¼Œæ ¼å¼ä¸º: ç”¨æˆ·å/ä»“åº“å")
            return

        # Check if the repo exists
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    GITHUB_API_URL.format(repo=repo), headers=self._get_github_headers()
                ) as resp:
                    if resp.status != 200:
                        yield event.plain_result(f"ä»“åº“ {repo} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
                        return

                    repo_data = await resp.json()
                    display_name = repo_data.get("full_name", repo)
        except Exception as e:
            logger.error(f"è®¿é—® GitHub API å¤±è´¥: {e}")
            yield event.plain_result(f"æ£€æŸ¥ä»“åº“æ—¶å‡ºé”™: {str(e)}")
            return

        # Set as default repo for this conversation
        self.default_repos[event.unified_msg_origin] = display_name
        self._save_default_repos()
        yield event.plain_result(f"å·²å°† {display_name} è®¾ä¸ºé»˜è®¤ä»“åº“")

    def _is_valid_repo(self, repo: str) -> bool:
        """Check if the repository name is valid"""
        return bool(re.match(r"[\w\-]+/[\w\-]+$", repo))

    async def _check_updates_periodically(self):
        """Periodically check for updates in subscribed repositories"""
        if self.enable_webhook:
            logger.debug("Webhook æ¨¡å¼å·²å¯ç”¨ï¼Œè·³è¿‡è½®è¯¢ä»»åŠ¡")
            return

        try:
            while True:
                try:
                    await self._check_all_repos()
                except Exception as e:
                    logger.error(f"æ£€æŸ¥ä»“åº“æ›´æ–°æ—¶å‡ºé”™: {e}")

                # Use configured check interval
                minutes = max(1, self.check_interval)  # Ensure at least 1 minute
                logger.debug(f"ç­‰å¾… {minutes} åˆ†é’Ÿåå†æ¬¡æ£€æŸ¥ä»“åº“æ›´æ–°")
                await asyncio.sleep(minutes * 60)
        except asyncio.CancelledError:
            logger.info("åœæ­¢æ£€æŸ¥ä»“åº“æ›´æ–°")

    async def _check_all_repos(self):
        """Check all subscribed repositories for updates"""
        if self.enable_webhook:
            return

        for repo in list(self.subscriptions.keys()):
            logger.info(f"æ­£åœ¨æ£€æŸ¥ä»“åº“ {repo} æ›´æ–°")
            if not self.subscriptions[repo]:  # Skip if no subscribers
                continue

            try:
                # Get the last check time for this repo
                last_check = self.last_check_time.get(repo, None)

                # Fetch new issues and PRs
                new_items = await self._fetch_new_items(repo, last_check)

                if new_items:
                    # Update last check time
                    self.last_check_time[repo] = datetime.now().isoformat()

                    # Notify subscribers about new items
                    await self._notify_subscribers(repo, new_items)
            except Exception as e:
                logger.error(f"æ£€æŸ¥ä»“åº“ {repo} æ›´æ–°æ—¶å‡ºé”™: {e}")

    async def _fetch_new_items(self, repo: str, last_check: str | None):
        """Fetch new issues and PRs from a repository since last check"""
        if not last_check:
            # If first time checking, just record current time and return empty list
            # Store as UTC timestamp without timezone info to avoid comparison issues
            self.last_check_time[repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"åˆå§‹åŒ–ä»“åº“ {repo} çš„æ—¶é—´æˆ³: {self.last_check_time[repo]}")
            return []

        try:
            # Always treat stored timestamps as UTC without timezone info
            last_check_dt = datetime.fromisoformat(last_check)

            # Ensure it's treated as naive datetime
            if hasattr(last_check_dt, "tzinfo") and last_check_dt.tzinfo is not None:
                # If it somehow has timezone info, convert to naive UTC
                last_check_dt = last_check_dt.replace(tzinfo=None)

            logger.info(f"ä»“åº“ {repo} çš„ä¸Šæ¬¡æ£€æŸ¥æ—¶é—´: {last_check_dt.isoformat()}")
            new_items = []

            # GitHub API returns both issues and PRs in the issues endpoint
            async with aiohttp.ClientSession() as session:
                try:
                    params = {
                        "sort": "created",
                        "direction": "desc",
                        "state": "all",
                        "per_page": 10,
                    }
                    async with session.get(
                        GITHUB_ISSUES_API_URL.format(repo=repo),
                        params=params,
                        headers=self._get_github_headers(),
                    ) as resp:
                        if resp.status == 200:
                            items = await resp.json()

                            for item in items:
                                # Convert GitHub's timestamp to naive UTC datetime for consistent comparison
                                github_timestamp = item["created_at"].replace("Z", "")
                                created_at = datetime.fromisoformat(github_timestamp)

                                # Always remove timezone info for comparison
                                created_at = created_at.replace(tzinfo=None)

                                logger.info(
                                    f"æ¯”è¾ƒ: ä»“åº“ {repo} çš„ item #{item['number']} åˆ›å»ºäº {created_at.isoformat()}, ä¸Šæ¬¡æ£€æŸ¥: {last_check_dt.isoformat()}"
                                )

                                if created_at > last_check_dt:
                                    logger.info(
                                        f"å‘ç°æ–°çš„ item #{item['number']} in {repo}"
                                    )
                                    new_items.append(item)
                                else:
                                    # Since items are sorted by creation time, we can break early
                                    logger.info(f"æ²¡æœ‰æ›´å¤šæ–° items in {repo}")
                                    break
                        else:
                            logger.error(
                                f"è·å–ä»“åº“ {repo} çš„ Issue/PR å¤±è´¥: {resp.status}: {await resp.text()}"
                            )
                except Exception as e:
                    logger.error(f"è·å–ä»“åº“ {repo} çš„ Issue/PR æ—¶å‡ºé”™: {e}")

            # Update the last check time to now (UTC without timezone info)
            if new_items:
                logger.info(f"æ‰¾åˆ° {len(new_items)} ä¸ªæ–°çš„ items åœ¨ {repo}")
            else:
                logger.info(f"æ²¡æœ‰æ‰¾åˆ°æ–°çš„ items åœ¨ {repo}")

            # Always update the timestamp after checking, regardless of whether we found items
            self.last_check_time[repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(f"æ›´æ–°ä»“åº“ {repo} çš„æ—¶é—´æˆ³ä¸º: {self.last_check_time[repo]}")

            return new_items
        except Exception as e:
            logger.error(f"è§£ææ—¶é—´æ—¶å‡ºé”™: {e}")
            # If we can't parse the time correctly, just return an empty list
            # and update the last check time to prevent continuous errors
            self.last_check_time[repo] = (
                datetime.utcnow().replace(microsecond=0).isoformat()
            )
            logger.info(
                f"å‡ºé”™åæ›´æ–°ä»“åº“ {repo} çš„æ—¶é—´æˆ³ä¸º: {self.last_check_time[repo]}"
            )
            return []

    async def _notify_subscribers(self, repo: str, new_items: list[dict[str, Any]]):
        """Notify subscribers about new issues and PRs"""
        if not new_items:
            return

        repo_key = self._resolve_repo_key(repo) or repo

        for subscriber_id in self.subscriptions.get(repo_key, []):
            try:
                # Create notification message
                for item in new_items:
                    item_type = "PR" if "pull_request" in item else "Issue"
                    message = (
                        f"[GitHub æ›´æ–°] ä»“åº“ {repo} æœ‰æ–°çš„{item_type}:\n"
                        f"#{item['number']} {item['title']}\n"
                        f"ä½œè€…: {item['user']['login']}\n"
                        f"é“¾æ¥: {item['html_url']}"
                    )

                    # Send message to subscriber
                    await self.context.send_message(
                        subscriber_id, MessageChain(chain=[Comp.Plain(message)])
                    )

                    # Add a small delay between messages to avoid rate limiting
                    await asyncio.sleep(1)
            except Exception as e:
                logger.error(f"å‘è®¢é˜…è€… {subscriber_id} å‘é€é€šçŸ¥æ—¶å‡ºé”™: {e}")

    async def handle_webhook_event(
        self, event_type: str, payload: dict[str, Any]
    ) -> None:
        """Process incoming GitHub webhook events."""
        if event_type == "ping":
            logger.info("æ”¶åˆ° GitHub Webhook ping äº‹ä»¶")
            return

        repo_info = payload.get("repository")
        if not isinstance(repo_info, dict):
            logger.warning("GitHub Webhook äº‹ä»¶ç¼ºå°‘ repository ä¿¡æ¯")
            return

        repo_full_name = repo_info.get("full_name")
        if not repo_full_name:
            logger.warning("GitHub Webhook äº‹ä»¶ç¼ºå°‘ä»“åº“å…¨å")
            return

        repo_key = self._resolve_repo_key(repo_full_name)
        if not repo_key:
            logger.debug(
                f"å¿½ç•¥ä»“åº“ {repo_full_name} çš„ Webhook äº‹ä»¶ {event_type}: æœªæ‰¾åˆ°å¯¹åº”è®¢é˜…"
            )
            return

        subscribers = self.subscriptions.get(repo_key, [])
        if not subscribers:
            logger.debug(
                f"ä»“åº“ {repo_full_name} æ²¡æœ‰è®¢é˜…è€…ï¼Œè·³è¿‡ Webhook äº‹ä»¶ {event_type}"
            )
            return

        sender = payload.get("sender")
        action = payload.get("action", "")
        message: str | None = None

        if event_type == "issues":
            issue = payload.get("issue")
            if isinstance(issue, dict):
                message = formatters.format_webhook_issue_message(
                    repo_full_name, action, issue, sender
                )
        elif event_type == "pull_request":
            pull_request = payload.get("pull_request")
            if isinstance(pull_request, dict):
                message = formatters.format_webhook_pr_message(
                    repo_full_name, action, pull_request, sender
                )
        elif event_type == "issue_comment":
            issue = payload.get("issue")
            comment = payload.get("comment")
            if isinstance(issue, dict) and isinstance(comment, dict):
                message = formatters.format_webhook_issue_comment_message(
                    repo_full_name, action, issue, comment, sender
                )
        elif event_type == "commit_comment":
            comment = payload.get("comment")
            if isinstance(comment, dict):
                message = formatters.format_webhook_commit_comment_message(
                    repo_full_name, action, comment, sender
                )
        elif event_type == "discussion":
            discussion = payload.get("discussion")
            if isinstance(discussion, dict):
                message = formatters.format_webhook_discussion_message(
                    repo_full_name, action, discussion, sender
                )
        elif event_type == "discussion_comment":
            discussion = payload.get("discussion")
            comment = payload.get("comment")
            if isinstance(discussion, dict) and isinstance(comment, dict):
                message = formatters.format_webhook_discussion_comment_message(
                    repo_full_name, action, discussion, comment, sender
                )
        elif event_type == "fork":
            message = formatters.format_webhook_fork_message(
                repo_full_name, payload.get("forkee"), sender
            )
        elif event_type == "pull_request_review_comment":
            pull_request = payload.get("pull_request")
            comment = payload.get("comment")
            if isinstance(pull_request, dict) and isinstance(comment, dict):
                message = formatters.format_webhook_pr_review_comment_message(
                    repo_full_name, action, pull_request, comment, sender
                )
        elif event_type == "pull_request_review":
            pull_request = payload.get("pull_request")
            review = payload.get("review")
            if isinstance(pull_request, dict) and isinstance(review, dict):
                message = formatters.format_webhook_pr_review_message(
                    repo_full_name, action, pull_request, review, sender
                )
        elif event_type == "pull_request_review_thread":
            pull_request = payload.get("pull_request")
            thread = payload.get("thread")
            if isinstance(pull_request, dict) and isinstance(thread, dict):
                message = formatters.format_webhook_pr_review_thread_message(
                    repo_full_name, action, pull_request, thread, sender
                )
        elif event_type == "star":
            message = formatters.format_webhook_star_message(
                repo_full_name, action, sender
            )
        elif event_type == "create":
            message = formatters.format_webhook_create_message(
                repo_full_name, payload, sender
            )
        else:
            logger.debug(f"æš‚ä¸å¤„ç†çš„ GitHub Webhook äº‹ä»¶ç±»å‹: {event_type}")
            return

        if not message:
            logger.debug(f"Webhook äº‹ä»¶ {event_type} æœªç”Ÿæˆé€šçŸ¥ï¼Œå¯èƒ½æ˜¯ä¸æ”¯æŒçš„ action")
            return

        for subscriber_id in subscribers:
            try:
                await self.context.send_message(
                    subscriber_id, MessageChain(chain=[Comp.Plain(message)])
                )
                await asyncio.sleep(1)
            except Exception as exc:
                logger.error(f"å‘è®¢é˜…è€… {subscriber_id} å‘é€ Webhook é€šçŸ¥æ—¶å‡ºé”™: {exc}")

    @filter.command("ghissue", alias={"ghis"})
    async def get_issue_details(self, event: AstrMessageEvent, issue_ref: str):
        """è·å– GitHub Issue è¯¦æƒ…ã€‚æ ¼å¼ï¼š/ghissue ç”¨æˆ·å/ä»“åº“å#123 æˆ– /ghissue 123 (ä½¿ç”¨é»˜è®¤ä»“åº“)"""
        repo, issue_number = self._parse_issue_reference(
            issue_ref, event.unified_msg_origin
        )
        if not repo or not issue_number:
            yield event.plain_result(
                "è¯·æä¾›æœ‰æ•ˆçš„ Issue å¼•ç”¨ï¼Œæ ¼å¼ä¸ºï¼šç”¨æˆ·å/ä»“åº“å#123 æˆ–çº¯æ•°å­—(ä½¿ç”¨é»˜è®¤ä»“åº“)"
            )
            return

        try:
            issue_data = await self._fetch_issue_data(repo, issue_number)
            if not issue_data:
                yield event.plain_result(
                    f"æ— æ³•è·å– Issue {repo}#{issue_number} çš„ä¿¡æ¯ï¼Œå¯èƒ½ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™"
                )
                return

            # Format and send the issue details
            result = formatters.format_issue_details(repo, issue_data)
            yield event.plain_result(result)

            # Send the issue card image if available
            if issue_data.get("html_url"):
                hash_value = uuid.uuid4().hex
                url_path = issue_data["html_url"].replace("https://github.com/", "")
                card_url = GITHUB_REPO_OPENGRAPH.format(
                    hash=hash_value, appendix=url_path
                )
                try:
                    yield event.image_result(card_url)
                except Exception as e:
                    logger.error(f"ä¸‹è½½ Issue å¡ç‰‡å›¾ç‰‡å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"è·å– Issue è¯¦æƒ…æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"è·å– Issue è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")

    @filter.command("ghpr")
    async def get_pr_details(self, event: AstrMessageEvent, pr_ref: str):
        """è·å– GitHub PR è¯¦æƒ…ã€‚æ ¼å¼ï¼š/ghpr ç”¨æˆ·å/ä»“åº“å#123 æˆ– /ghpr 123 (ä½¿ç”¨é»˜è®¤ä»“åº“)"""
        repo, pr_number = self._parse_issue_reference(pr_ref, event.unified_msg_origin)
        if not repo or not pr_number:
            yield event.plain_result(
                "è¯·æä¾›æœ‰æ•ˆçš„ PR å¼•ç”¨ï¼Œæ ¼å¼ä¸ºï¼šç”¨æˆ·å/ä»“åº“å#123 æˆ–çº¯æ•°å­—(ä½¿ç”¨é»˜è®¤ä»“åº“)"
            )
            return

        try:
            pr_data = await self._fetch_pr_data(repo, pr_number)
            if not pr_data:
                yield event.plain_result(
                    f"æ— æ³•è·å– PR {repo}#{pr_number} çš„ä¿¡æ¯ï¼Œå¯èƒ½ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™"
                )
                return

            # Format and send the PR details
            result = formatters.format_pr_details(repo, pr_data)
            yield event.plain_result(result)

            # Send the PR card image if available
            if pr_data.get("html_url"):
                hash_value = uuid.uuid4().hex
                url_path = pr_data["html_url"].replace("https://github.com/", "")
                card_url = GITHUB_REPO_OPENGRAPH.format(
                    hash=hash_value, appendix=url_path
                )
                try:
                    yield event.image_result(card_url)
                except Exception as e:
                    logger.error(f"ä¸‹è½½ PR å¡ç‰‡å›¾ç‰‡å¤±è´¥: {e}")

        except Exception as e:
            logger.error(f"è·å– PR è¯¦æƒ…æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"è·å– PR è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")

    def _parse_issue_reference(
        self, reference: str, msg_origin: str | None = None
    ) -> tuple[str | None, str | None]:
        """Parse issue/PR reference string in various formats"""
        # Try format 'owner/repo#number' or 'owner/repo number'
        match = re.match(r"([\w\-]+/[\w\-]+)(?:#|\s+)(\d+)$", reference)
        if match:
            return match.group(1), match.group(2)

        # Try format 'owner/repo/number' (without spaces)
        match = re.match(r"([\w\-]+/[\w\-]+)/(\d+)$", reference)
        if match:
            return match.group(1), match.group(2)

        # If reference is just a number, try to use default repo or a subscribed repo
        if reference.isdigit():
            # First check for default repo for this conversation
            if msg_origin and msg_origin in self.default_repos:
                return self.default_repos[msg_origin], reference

            # Next check if there's exactly one subscription
            if msg_origin:
                user_subscriptions = []
                for repo, subscribers in self.subscriptions.items():
                    if msg_origin in subscribers:
                        user_subscriptions.append(repo)

                if len(user_subscriptions) == 1:
                    return user_subscriptions[0], reference
                elif len(user_subscriptions) > 1:
                    logger.debug(
                        f"Found multiple subscriptions for {msg_origin}, can't determine default repo"
                    )

        return None, None

    def _parse_readme_reference(self, reference: str) -> str | None:
        """Parse readme reference string."""
        # Match 'owner/repo' and optional '#...' or ' ...' part
        match = re.match(r"([\w\-]+/[\w\-]+)", reference)
        if match:
            return match.group(1)
        return None

    @filter.command("ghreadme")
    async def get_readme_details(self, event: AstrMessageEvent, readme_ref: str):
        """æŸ¥è¯¢æŒ‡å®šä»“åº“çš„ README ä¿¡æ¯ã€‚ä¾‹å¦‚: /ghreadme ç”¨æˆ·å/ä»“åº“å"""
        repo = self._parse_readme_reference(readme_ref)
        if not repo:
            yield event.plain_result("è¯·æä¾›æœ‰æ•ˆçš„ä»“åº“å¼•ç”¨ï¼Œæ ¼å¼ä¸ºï¼šç”¨æˆ·å/ä»“åº“å")
            return

        try:
            readme_data = await self._fetch_readme_data(repo)
            if not readme_data:
                yield event.plain_result(
                    f"æ— æ³•è·å–ä»“åº“ {repo} çš„ README ä¿¡æ¯ï¼Œå¯èƒ½ä¸å­˜åœ¨æˆ–æ— è®¿é—®æƒé™"
                )
                return

            # Decode content from base64
            content_base64 = readme_data.get("content", "")
            try:
                readme_content = base64.b64decode(content_base64).decode("utf-8")
            except Exception as e:
                logger.error(f"è§£ç  README å†…å®¹å¤±è´¥: {e}")
                yield event.plain_result(f"è§£ç ä»“åº“ {repo} çš„ README å†…å®¹æ—¶å‡ºé”™")
                return

            # **[REMOVED]** Truncation logic is removed.

            header = f"ğŸ“– {repo} çš„ README\n\n"
            full_text = header + readme_content

            # Render text to image
            try:
                image_url = await self.text_to_image(full_text)
                yield event.image_result(image_url)
            except Exception as e:
                logger.error(f"æ¸²æŸ“ README å›¾ç‰‡å¤±è´¥: {e}")
                # Fallback to plain text if image rendering fails
                yield event.plain_result(full_text)

        except Exception as e:
            logger.error(f"è·å– README è¯¦æƒ…æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"è·å– README è¯¦æƒ…æ—¶å‡ºé”™: {str(e)}")

    async def _fetch_readme_data(self, repo: str) -> dict[str, Any] | None:
        """Fetch README data from GitHub API"""
        async with aiohttp.ClientSession() as session:
            try:
                url = GITHUB_README_API_URL.format(repo=repo)
                async with session.get(url, headers=self._get_github_headers()) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.error(f"è·å– README {repo} å¤±è´¥: {resp.status}")
                        return None
            except Exception as e:
                logger.error(f"è·å– README {repo} æ—¶å‡ºé”™: {e}")
                return None

    async def _fetch_issue_data(
        self, repo: str, issue_number: str
    ) -> dict[str, Any] | None:
        """Fetch issue data from GitHub API"""
        async with aiohttp.ClientSession() as session:
            try:
                url = GITHUB_ISSUE_API_URL.format(repo=repo, issue_number=issue_number)
                async with session.get(url, headers=self._get_github_headers()) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.error(
                            f"è·å– Issue {repo}#{issue_number} å¤±è´¥: {resp.status}"
                        )
                        return None
            except Exception as e:
                logger.error(f"è·å– Issue {repo}#{issue_number} æ—¶å‡ºé”™: {e}")
                return None

    async def _fetch_pr_data(self, repo: str, pr_number: str) -> dict[str, Any] | None:
        """Fetch PR data from GitHub API"""
        async with aiohttp.ClientSession() as session:
            try:
                url = GITHUB_PR_API_URL.format(repo=repo, pr_number=pr_number)
                async with session.get(url, headers=self._get_github_headers()) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.error(f"è·å– PR {repo}#{pr_number} å¤±è´¥: {resp.status}")
                        return None
            except Exception as e:
                logger.error(f"è·å– PR {repo}#{pr_number} æ—¶å‡ºé”™: {e}")
                return None

    @filter.command("ghlimit", alias={"ghrate"})
    async def check_rate_limit(self, event: AstrMessageEvent):
        """æŸ¥çœ‹ GitHub API é€Ÿç‡é™åˆ¶çŠ¶æ€"""
        try:
            rate_limit_data = await self._fetch_rate_limit()
            if not rate_limit_data:
                yield event.plain_result("æ— æ³•è·å– GitHub API é€Ÿç‡é™åˆ¶ä¿¡æ¯")
                return

            # Format and send the rate limit details
            result = self._format_rate_limit(rate_limit_data)
            yield event.plain_result(result)

        except Exception as e:
            logger.error(f"è·å– API é€Ÿç‡é™åˆ¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"è·å– API é€Ÿç‡é™åˆ¶ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")

    async def _fetch_rate_limit(self) -> dict[str, Any] | None:
        """Fetch rate limit information from GitHub API"""
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(
                    GITHUB_RATE_LIMIT_URL, headers=self._get_github_headers()
                ) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        logger.error(f"è·å– API é€Ÿç‡é™åˆ¶ä¿¡æ¯å¤±è´¥: {resp.status}")
                        return None
            except Exception as e:
                logger.error(f"è·å– API é€Ÿç‡é™åˆ¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
                return None

    def _format_rate_limit(self, rate_limit_data: dict[str, Any]) -> str:
        """Format rate limit data for display"""
        if not rate_limit_data or "resources" not in rate_limit_data:
            return "è·å–åˆ°çš„é€Ÿç‡é™åˆ¶æ•°æ®æ— æ•ˆ"

        resources = rate_limit_data["resources"]
        core = resources.get("core", {})
        search = resources.get("search", {})
        graphql = resources.get("graphql", {})

        # Convert timestamps to datetime objects
        core_reset = datetime.fromtimestamp(core.get("reset", 0))
        search_reset = datetime.fromtimestamp(search.get("reset", 0))
        graphql_reset = datetime.fromtimestamp(graphql.get("reset", 0))

        # Calculate time until reset
        now = datetime.now()
        core_minutes = max(0, (core_reset - now).total_seconds() // 60)
        search_minutes = max(0, (search_reset - now).total_seconds() // 60)
        graphql_minutes = max(0, (graphql_reset - now).total_seconds() // 60)

        # Format the result
        result = (
            "ğŸ“Š GitHub API é€Ÿç‡é™åˆ¶çŠ¶æ€\n\n"
            "ğŸ’» æ ¸å¿ƒ API (repositories, issues, etc):\n"
            f"  å‰©ä½™è¯·æ±‚æ•°: {core.get('remaining', 0)}/{core.get('limit', 0)}\n"
            f"  é‡ç½®æ—¶é—´: {core_reset.strftime('%H:%M:%S')} (çº¦ {int(core_minutes)} åˆ†é’Ÿå)\n\n"
            "ğŸ” æœç´¢ API:\n"
            f"  å‰©ä½™è¯·æ±‚æ•°: {search.get('remaining', 0)}/{search.get('limit', 0)}\n"
            f"  é‡ç½®æ—¶é—´: {search_reset.strftime('%H:%M:%S')} (çº¦ {int(search_minutes)} åˆ†é’Ÿå)\n\n"
            "ğŸ“ˆ GraphQL API:\n"
            f"  å‰©ä½™è¯·æ±‚æ•°: {graphql.get('remaining', 0)}/{graphql.get('limit', 0)}\n"
            f"  é‡ç½®æ—¶é—´: {graphql_reset.strftime('%H:%M:%S')} (çº¦ {int(graphql_minutes)} åˆ†é’Ÿå)\n"
        )

        # Add information about authentication status
        if self.github_token:
            result += "\nâœ… å·²ä½¿ç”¨ GitHub Token è¿›è¡Œèº«ä»½éªŒè¯ï¼Œé€Ÿç‡é™åˆ¶è¾ƒé«˜"
        else:
            result += (
                "\nâš ï¸ æœªä½¿ç”¨ GitHub Tokenï¼Œé€Ÿç‡é™åˆ¶è¾ƒä½ã€‚å¯åœ¨é…ç½®ä¸­æ·»åŠ  Token ä»¥æé«˜é™åˆ¶"
            )

        return result

    # TODO: svg2png
    # @filter.command("ghstar")
    # async def ghstar(self, event: AstrMessageEvent, identifier: str):
    #     '''æŸ¥çœ‹ GitHub ä»“åº“çš„ Star è¶‹åŠ¿å›¾ã€‚å¦‚: /ghstar Soulter/AstrBot'''
    #     url = STAR_HISTORY_URL.format(identifier=identifier)
    #     # download svg
    #     fpath = "data/temp/{identifier}.svg".format(identifier=identifier.replace("/",
    #         "_"))
    #     await download_file(url, fpath)
    #     # convert to png
    #     png_fpath = fpath.replace(".svg", ".png")
    #     cairosvg.svg2png(url=fpath, write_to=png_fpath)
    #     # send image
    #     yield event.image_result(png_fpath)

    async def terminate(self):
        """Cleanup and save data before termination"""
        self._save_subscriptions()
        self._save_default_repos()
        if self.task:
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass

        if self.webhook_server:
            await self.webhook_server.stop()
        logger.info("GitHub Cards Plugin å·²ç»ˆæ­¢")
